#!/usr/bin/python3
#
# Copyright 2020 Dustin Kleckner
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import numpy as np
import numba
from .. import VolumetricMovie, VolumeProperties
from xml.etree import ElementTree
import re
import warnings
import struct

# A homegrown LZ4 decompresser, which uses JIT through numba.
# It's really fast!  Typically performance is several times that of the LZ4
#   library!  A few GB/s of decompression speed is easily acheivable on
#   commodity hardware.
@numba.jit(nopython=True, parallel=True, cache=True)
def numba_decompress_blocks(input, num_blocks, block_size, last_block_size, block_sizes, block_ends, output):
    for p in numba.prange(num_blocks):
        if p == 0:
            i = numba.uint64(0)
        else:
            i = numba.uint64(block_ends[p - numba.uint(1)])

        block_end = numba.uint64(block_ends[p])
        j = numba.uint64(block_size * p)

        if (p == (num_blocks - numba.uint8(1))):
            end = j + numba.uint64(last_block_size)
        else:
            end = j + numba.uint64(block_size)

        while ((j < end) and (i < block_end)):
            t1 = numba.uint16((input[i] & 0xF0) >> 4)
            t2 = numba.uint16((input[i] & 0x0F) + 4)
            i += numba.uint8(1)

            if (t1 == 15):
                while input[i] == 255:
                    t1 += numba.uint8(input[i])
                    i += numba.uint8(1)

                t1 += numba.uint8(input[i])
                i += numba.uint8(1)

            for n in range(t1):
                output[j] = input[i]
                i += numba.uint8(1)
                j += numba.uint8(1)

            if (j >= end): break

            off = numba.uint16(input[i]) + (numba.uint16(input[i+1]) << 8)
            i += numba.uint8(2)

            if (t2 == 19):
                while input[i] == 255:
                    t2 += numba.uint8(input[i])
                    i += numba.uint8(1)

                t2 += numba.uint8(input[i])
                i += numba.uint8(1)

            for n in range(t2):
                output[j] = output[j - off]
                j += numba.uint8(1)


class VTIMovie(VolumetricMovie):
    def __init__(self, fn, **kwargs):
        '''Load a VolumetricMovie from a VTI file.

        Parameters
        ----------
        fn : str
            Filename

        Any additional keywords are passed to the info directory, overriding
        any in the original file.  (Can be used, for example, to modify the
        perspective correction or other parameters.)
        '''

        self.filename = fn
        self.info = VolumeProperties()

        self.frame_offsets = []

        self.f = open(fn, 'rb')

        for event, elem in ElementTree.iterparse(self.f, events=['start', 'end']):
            # Read until we hit the AppendedData section.  Since this may
            #  contain raw data, it may no longer be valid XML after this point!
            # Also, you don't want to read in GB of data!
            if event == 'start' and elem.tag == 'AppendedData':
                break

            # Check for the completion of some important tags!
            if event == 'end':

                # These are tags created by the MUVI metadata writer.  They
                #   may not be present, which is ok too!  (This will be true
                #   if the file was generated by anything other than the MUVI
                #   software, in which case it may still be ok!)
                if elem.tag == 'VolumeProperties':
                    self.info.update(elem)
                    print(elem)


                # This is the main tag for the image data
                elif elem.tag == 'ImageData':
                    # There should only be one; we can check if we've already
                    #   populated the frame offsets, and if so issue a warning.
                    if len(self.frame_offsets):
                        print("Warning: found multiple ImageData objects; ignoring all those after the first.")
                        continue
                    else:

                        # Read the extent and spacing info from the ImageData tag
                        try:
                            extents = list(map(int, elem.get('WholeExtent').split()))
                            # print(type(extents[1] - extents[0]))
                            Nx = extents[1] - extents[0]
                            Ny = extents[3] - extents[2]
                            Nz = extents[5] - extents[4]
                            for i, key in enumerate(('Nx', 'Ny', 'Nz')):
                                N = extents[i*2+1] - extents[i*2]
                                if key in self.info:
                                    if self.info[key] != N:
                                        raise ValueError('Size of array in VolumeProperties does not match data - invalid file.')
                                else:
                                    self.info[key] = N

                        except:
                            raise ValueError("Invalid or missing 'WholeExtent' field in ImageData of VTK File '%s'" % (self.filename))

                        if len(extents) != 6:
                            raise ValueError("'WholeExtent' field in ImageData of VTK File '%s' has wrong number of elements" % (self.filename))

                        if 'spacing' in elem.keys():
                            try:
                                spacing = np.map(float, elem.get('Spacing').split())
                            except:
                                raise ValueError("Invalid 'Spacing' field in ImageData of VTK File '%s'" % (self.filename))

                            if len(spacing) != 3:
                                raise ValueError("'Spacing' field in ImageData of VTK File '%s' has wrong number of elements" % (self.filename))
                        else:
                            spacing = np.ones(3)

                        # Find the Piece tags inside the ImageData
                        pieces = [e for e in elem if e.tag == 'Piece']

                        # The reader only (currently) supports a single Piece
                        #   tag -- i.e. the data should be in one chunk
                        if len(pieces) != 1:
                            raise ValueError("'ImageData' tag in VTK file '%s' should contain exactly 1 piece (found %d).\n(Multipiece files not supported at this time.)" % (self.filename, len(pieces)))

                        pieces = [e for e in pieces[0] if e.tag == 'CellData']
                        if len(pieces) != 1:
                            raise ValueError("'Piece' tag in VTK file '%s' should contain exactly 1 'CellData' (found %d).\n(Multiimage not supported at this time.)" % (self.filename, len(pieces)))

                        for data in pieces[0]:
                            if data.tag == 'DataArray':
                                if data.get('format').lower() != "appended":
                                    raise ValueError('VTK Reader only supports VTI files with appended data.')
                                if data.get('TimeStep') != str(len(self.frame_offsets)):
                                    warnings.warn('Frames appear to be out of order in file; may display incorrectly.')
                                self.frame_offsets.append(int(data.get('offset')))

        # print(self.frame_offsets)
        end = self.f.tell()

        self.f.seek(0)
        header = self.f.read(end + 256)
        m = re.search(b'<\s*AppendedData.*?>.*?_', header, flags=re.DOTALL)
        if not m:
            raise ValueError('Failed to find AppendedData section in "%s".  Is this a valid file?' % self.filename)
        self.binary_start = m.end()
        self.frame_offsets = [offset + self.binary_start for offset in self.frame_offsets]

        self.info.update(kwargs)
        print(self.info)
        self.validate_info()


    def get_volume(self, i):
        if not hasattr(self, 'shape'):
            if 'channels' in self.info:
                self.shape = (self.info['Nx'], self.info['Ny'], self.info['Nz'], self.info['channels'])
            else:
                self.shape = (self.info['Nx'], self.info['Ny'], self.info['Nz'])

        # if long_header:
        header_type = np.dtype("<u8")
        sc = 'Q'
        # else:
        #     data_type = np.dtype("<u4")
        #     sc = 'I'


        data_size = np.uint64(header_type.itemsize)
        header_size = np.uint64(3 * data_size)

        self.f.seek(self.frame_offsets[i])
        num_blocks, block_size, last_block_size = struct.unpack('<3' + sc, self.f.read(header_size))
        data_start = np.uint64((3 + num_blocks) * data_size)

        block_sizes = np.frombuffer(self.f.read(data_start-header_size), dtype=header_type)
        block_ends = np.cumsum(block_sizes)
        # print(block_ends)

        # output = np.empty((num_blocks - 1) * block_size + last_block_size, dtype='u1')

        # print('Num blocks', num_blocks)
        # print(type(input[data_start:]))
        # print(block_sizes)
        # print(block_ends)

        # numba_decompress_blocks(np.frombuffer(input[data_start:], dtype='u1'), num_blocks, block_size, last_block_size, block_sizes, block_ends, output)


        block_starts = np.concatenate([[np.uint64(0)], block_ends[:-1]])

        # output = bytearray((num_blocks - 1) * block_size + last_block_size)

        # if use_numba:
        output = np.empty((num_blocks - 1) * block_size + last_block_size, dtype='u1')
        numba_decompress_blocks(np.frombuffer(self.f.read(block_ends[-1]), dtype='u1'), num_blocks, block_size, last_block_size, block_sizes, block_ends, output)
        # else:
        #     def decompress_block(args):
        #         cs, ce, os, oe = args
        #         output[os:oe] = lz4.block.decompress(input[cs:ce], oe-os)
        #
        #     output = bytearray((num_blocks - 1) * block_size + last_block_size)
        #
        #     with concurrent.futures.ThreadPoolExecutor() as exec:
        #         dat_comp = exec.map(decompress_block, (
        #             (data_start + block_starts[n],
        #              data_start + block_ends[n],
        #              n * block_size,
        #              min((n+1)*block_size, len(output))
        #             ) for n in range(num_blocks)
        #         ))
        #
        #     output = np.frombuffer(output, dtype='u1')

        # return b''.join(lz4.block.decompress(input[data_start + block_starts[n]:data_start + block_ends[n]], block_size) for n in range(num_blocks))

        return output.view(self.info['dtype']).reshape(self.shape)


    def close(self):
        self.f.close()
        del self.f
